{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0f8fade-cfaf-41f0-a242-9a07c973a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e043d897-b064-437c-9f7f-334c6b5f96bd",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aedb4fa-4dbd-43be-8448-b1c17cc671f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-835111600377>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_with_labels['name'][i] = re.sub('\"', '', name)\n",
      "<ipython-input-2-835111600377>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tit_test['Name'][i] = re.sub('\"', '', name)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#https://www.kaggle.com/c/titanic/data\n",
    "tit_sub = pd.read_csv('./data/Titanic/gender_submission.csv')\n",
    "tit_train = pd.read_csv('./data/Titanic/train.csv')\n",
    "tit_test = pd.read_csv('./data/Titanic/test.csv')\n",
    "df_train_final = pd.read_pickle(\"./data/Titanic/df_train_final\")\n",
    "df_test_final = pd.read_pickle(\"./data/Titanic/df_test_final\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_cols = ['Age', 'Fare', 'Name_Length', 'Family_Size', 'Ticket_Frequency', 'Fare_Family_Size', 'Fare_Cat_Pclass']\n",
    "std = StandardScaler()\n",
    "std.fit(df_train_final[scaler_cols])\n",
    "df_train_final.loc[:, scaler_cols] = std.transform(df_train_final[scaler_cols])\n",
    "df_test_final.loc[:, scaler_cols] = std.transform(df_test_final[scaler_cols])\n",
    "\n",
    "features = ['Pclass', 'Sex', 'Age', 'Fare', 'Title', 'Name_Length', 'Emb_C',\n",
    "       'Emb_Q', 'Emb_S', 'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs',\n",
    "       'Title_Other', 'Title_Royal', 'Family_Size',\n",
    "       'Family_Friends_Surv_Rate', 'Cabin_Clean',\n",
    "       'Ticket_Frequency', 'Tkt_AS', 'Tkt_C', 'Tkt_CA',\n",
    "       'Tkt_CASOTON', 'Tkt_FC', 'Tkt_FCC', 'Tkt_Fa', 'Tkt_LINE', \n",
    "       'Tkt_NUM', 'Tkt_PC', 'Tkt_PP', 'Tkt_PPP', 'Tkt_SC', 'Tkt_SCA',\n",
    "       'Tkt_SCAH', 'Tkt_SCAHBasle', 'Tkt_SCOW', 'Tkt_SCPARIS', 'Tkt_SCParis',\n",
    "       'Tkt_SOC', 'Tkt_SOP', 'Tkt_SOPP', 'Tkt_SOTONO', 'Tkt_SOTONOQ', 'Tkt_SP',\n",
    "       'Tkt_STONO', 'Tkt_SWPP', 'Tkt_WC', 'Tkt_WEP', 'Fare_Cat', 'Child', 'Senior']\n",
    "\n",
    "features_train = ['Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Title', 'Name_Length', 'Emb_C',\n",
    "       'Emb_Q', 'Emb_S', 'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs',\n",
    "       'Title_Other', 'Title_Royal', 'Family_Size',\n",
    "       'Family_Friends_Surv_Rate', 'Cabin_Clean',\n",
    "       'Ticket_Frequency', 'Tkt_AS', 'Tkt_C', 'Tkt_CA',\n",
    "       'Tkt_CASOTON', 'Tkt_FC', 'Tkt_FCC', 'Tkt_Fa', 'Tkt_LINE',\n",
    "       'Tkt_NUM', 'Tkt_PC', 'Tkt_PP', 'Tkt_PPP', 'Tkt_SC', 'Tkt_SCA',\n",
    "       'Tkt_SCAH', 'Tkt_SCAHBasle', 'Tkt_SCOW', 'Tkt_SCPARIS', 'Tkt_SCParis',\n",
    "       'Tkt_SOC', 'Tkt_SOP', 'Tkt_SOPP', 'Tkt_SOTONO', 'Tkt_SOTONOQ', 'Tkt_SP',\n",
    "       'Tkt_STONO', 'Tkt_SWPP', 'Tkt_WC', 'Tkt_WEP', 'Fare_Cat', 'Child', 'Senior']\n",
    "\n",
    "df_train_final = df_train_final[features_train]\n",
    "df_test_final = df_test_final[features]\n",
    "\n",
    "# train/test/val split\n",
    "features = df_test_final.columns.to_list()\n",
    "X_train_df = df_train_final[features]\n",
    "Y_train = df_train_final['Survived']\n",
    "X_test_df = df_test_final.reset_index(drop=True)\n",
    "\n",
    "c=pd.read_csv('./data/Titanic/titanic_test_labels.csv')\n",
    "test_data_with_labels = c.copy()\n",
    "for i, name in enumerate(test_data_with_labels['name']):\n",
    "    if '\"' in name:\n",
    "        test_data_with_labels['name'][i] = re.sub('\"', '', name)\n",
    "for i, name in enumerate(tit_test['Name']):\n",
    "    if '\"' in name:\n",
    "        tit_test['Name'][i] = re.sub('\"', '', name)\n",
    "survived = []\n",
    "for name in tit_test['Name']:\n",
    "    survived.append(int(test_data_with_labels.loc[test_data_with_labels['name'] == name]['survived'].values[-1]))\n",
    "Y_test = pd.Series(survived,index=X_test_df.index)\n",
    "\n",
    "Y_train = Y_train.to_numpy()\n",
    "Y_test = Y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-vanilla",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "233f2973-6e8b-42e6-924d-1960d24cb4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "bst = pickle.load(open('./models/XGBoost_Titanic.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e23a754-ca34-41ee-94a1-60576985c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(X_train_df.columns)+['bb_proba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7865dab-be31-41a6-86be-de826aafd37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 0.9977553310886644\n",
      "test acc: 0.7200956937799043\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train_df.values, Y_train)\n",
    "dtest = xgb.DMatrix(X_test_df.values)\n",
    "y_train_pred = bst.predict(dtrain)\n",
    "y_test_pred = bst.predict(dtest)\n",
    "print('train acc:',np.mean(np.round(y_train_pred)==Y_train))\n",
    "print('test acc:',np.mean(np.round(y_test_pred)==Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01d02537-4eab-4b37-b154-3e6e5274a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.hstack((X_train_df.values,y_train_pred.reshape(-1,1)))\n",
    "X_test = np.hstack((X_test_df.values,y_test_pred.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "diagnostic-pacific",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFNN_VAE(\n",
      "  (fc1): Linear(in_features=52, out_features=26, bias=True)\n",
      "  (fc2): Linear(in_features=26, out_features=13, bias=True)\n",
      "  (fc3_mu): Linear(in_features=13, out_features=2, bias=True)\n",
      "  (fc3_logvar): Linear(in_features=13, out_features=2, bias=True)\n",
      "  (fc4): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=13, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc5): Sequential(\n",
      "    (0): Linear(in_features=13, out_features=26, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc6): Linear(in_features=26, out_features=52, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "## ---------------------- FFNN_CVAE ---------------------- ##\n",
    "\n",
    "class FFNN_VAE(nn.Module):\n",
    "    def __init__(self, input_shape, hidden, latent_dim=2):\n",
    "        super(FFNN_VAE, self).__init__()\n",
    "\n",
    "        # encoding components\n",
    "        self.fc1 = nn.Linear(input_shape,hidden[0])\n",
    "        self.fc2 = nn.Linear(hidden[0],hidden[1])\n",
    "        # Latent vectors mu and sigma\n",
    "        self.fc3_mu = nn.Linear(hidden[1], latent_dim)      \n",
    "        self.fc3_logvar = nn.Linear(hidden[1], latent_dim)  \n",
    "\n",
    "        # Sampling vector\n",
    "        self.fc4 = nn.Sequential(\n",
    "            nn.Linear(latent_dim+1, hidden[1]),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.fc5 = nn.Sequential(\n",
    "            nn.Linear(hidden[1], hidden[0]),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.fc6 = nn.Linear(hidden[0], input_shape)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        mu, logvar = self.fc3_mu(x), self.fc3_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z, y):\n",
    "        x = torch.cat((z,y), dim=1)\n",
    "        x = self.fc4(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "# hyperparameters\n",
    "latent_dim = 2    # latent dim extracted \n",
    "hidden = [26,13]\n",
    "\n",
    "# Create Model\n",
    "FFNN_VAE_model = FFNN_VAE(X_train.shape[1], hidden=hidden, latent_dim=latent_dim)\n",
    "print(FFNN_VAE_model)\n",
    "\n",
    "FFNN_VAE_model.load_state_dict(torch.load('./models/CVAE_Titanic.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "optional-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    FFNN_VAE_model.eval()\n",
    "    z_train, mu, logvar = FFNN_VAE_model(torch.tensor(X_train,dtype=torch.float32))\n",
    "    z_test, mu, logvar = FFNN_VAE_model(torch.tensor(X_test,dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55b64f0a-360c-477d-95a3-de44431da683",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = z_test[:, 0].min() - 0.1, z_test[:, 0].max() + 0.1\n",
    "y_min, y_max = z_test[:, 1].min() - 0.1, z_test[:, 1].max() + 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-andrew",
   "metadata": {},
   "source": [
    "# APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "actual-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "shap_fig = go.Figure()\n",
    "clustering_fig = go.Figure()\n",
    "violin_plot = go.Figure()\n",
    "\n",
    "colorscale = px.colors.diverging.RdBu[::-1]\n",
    "#[[0, '#3b4cc0'],[1, '#b40426']]\n",
    "\n",
    "shap_fig.add_trace(go.Scatter(x=z_train[:, 0].numpy(), \n",
    "                              y=z_train[:, 1].numpy(),\n",
    "                              mode='markers',\n",
    "                              marker=dict(\n",
    "                                 size=10,\n",
    "                                 symbol='circle',\n",
    "                                 color=y_train_pred, \n",
    "                                 opacity=0.3,\n",
    "                                 cmid=0.5,\n",
    "                                 colorscale=colorscale,\n",
    "                                 colorbar=dict(\n",
    "                                     title=\"% Survival\")\n",
    "                              )))\n",
    "\n",
    "clustering_fig.add_trace(go.Scatter(x=z_train[:, 0].numpy(),\n",
    "                                    y=z_train[:, 1].numpy(),\n",
    "                                    mode='markers',\n",
    "                                    marker=dict(\n",
    "                                        size=10,\n",
    "                                        symbol='circle',\n",
    "                                        color=y_train_pred, \n",
    "                                        cmid=0.5,\n",
    "                                        opacity=0.5,\n",
    "                                        colorscale=colorscale,\n",
    "                                        colorbar=dict(title=\"% Survival\")\n",
    "                                    )))\n",
    "\n",
    "violin_plot.add_trace(go.Violin(name='left',\n",
    "                      side='negative',\n",
    "                      line_color='blue',\n",
    "                      bandwidth=0.25,\n",
    "                      points=False)\n",
    "             )\n",
    "violin_plot.add_trace(go.Violin(name='right',\n",
    "                      side='positive',\n",
    "                      line_color='orange',\n",
    "                      bandwidth=0.25,\n",
    "                      points=False)\n",
    "             )\n",
    "violin_plot.update_traces(meanline_visible=True)\n",
    "violin_plot.update_layout(violingap=0, \n",
    "                          violinmode='overlay',\n",
    "                          template='plotly_white');\n",
    "\n",
    "shap_fig.add_trace(go.Scatter(x=[0], y=[0] ,mode='markers',name='pointer',showlegend=False,\n",
    "                         marker=dict(\n",
    "                             size=30,\n",
    "                             symbol='x',\n",
    "                             color='#000000',\n",
    "                             line=dict(width=1,\n",
    "                                        color='white')\n",
    "                         )))\n",
    "\n",
    "shap_fig.add_trace(go.Scatter(x=[0], y=[0] ,mode='markers',name='expected_value',showlegend=False,\n",
    "                         marker=dict(\n",
    "                             size=35,\n",
    "                             symbol='triangle-up',\n",
    "                             color='#a834e7',\n",
    "                             line=dict(width=1,\n",
    "                                       color='white'))))\n",
    "\n",
    "names = ['vector_0','vector_1','vector_2','vector_3','vector_4','vector_5','vector_6','vector_7','vector_8','vector_9']\n",
    "\n",
    "annotations = [\n",
    "    go.layout.Annotation(\n",
    "            #start\n",
    "            x=0, \n",
    "            y=0,\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "            #end\n",
    "            ax=0, \n",
    "            ay=0,\n",
    "            axref = \"x\", \n",
    "            ayref = \"y\",\n",
    "            showarrow=True,\n",
    "            arrowside='start',\n",
    "            arrowhead=2, # type od head [0,8]\n",
    "            arrowsize=1, # head dimension \n",
    "            arrowwidth=2, # arrow dimension\n",
    "            arrowcolor=\"#000000\",\n",
    "            name=name,\n",
    "            text='  ',\n",
    "            hovertext='baseline',\n",
    "            font=dict(\n",
    "                family=\"Courier New, monospace\",\n",
    "                size=1,\n",
    "                color=\"#ffffff\"\n",
    "            ),\n",
    "            bgcolor='#ff7f0e'\n",
    "            ) for name in names]+[\n",
    "     go.layout.Annotation(\n",
    "            #start\n",
    "            x=0, \n",
    "            y=0,\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "            #end\n",
    "            ax=0, \n",
    "            ay=0,\n",
    "            axref = \"x\", \n",
    "            ayref = \"y\",\n",
    "            showarrow=True,\n",
    "            arrowside='start',\n",
    "            arrowhead=2, # type od head [0,8]\n",
    "            arrowsize=1, # head dimension \n",
    "            arrowwidth=2, # arrow dimension\n",
    "            arrowcolor=\"#000000\",\n",
    "            name='others_contrib',\n",
    "            text='  ',\n",
    "            hovertext='other contributions',\n",
    "            font=dict(\n",
    "                family=\"Courier New, monospace\",\n",
    "                size=1,\n",
    "                color=\"#ffffff\"\n",
    "            ),\n",
    "            bgcolor='#ff7f0e'\n",
    "            )\n",
    "]\n",
    "\n",
    "clustering_fig.update_layout(\n",
    "    dragmode='lasso',\n",
    "    showlegend=False,\n",
    "    autosize=True,\n",
    "    template='plotly_white',\n",
    "    margin=dict(\n",
    "    l=5,\n",
    "    r=0,\n",
    "    b=5,\n",
    "    t=10,\n",
    "    pad=0\n",
    "))\n",
    "\n",
    "clustering_fig.update_xaxes(\n",
    "    range=[x_min, x_max],  \n",
    ")\n",
    "\n",
    "clustering_fig.update_yaxes(\n",
    "    scaleanchor = \"x\",\n",
    "    scaleratio = 1,\n",
    "  )\n",
    "\n",
    "shap_fig.update_layout(\n",
    "    showlegend=False,\n",
    "    annotations=annotations,\n",
    "    autosize=True,\n",
    "    #height=700,\n",
    "    #width=700,\n",
    "    template='plotly_white',\n",
    "    margin=dict(\n",
    "    l=5,\n",
    "    r=0,\n",
    "    b=5,\n",
    "    t=10,\n",
    "    pad=0\n",
    "))\n",
    "\n",
    "shap_fig.update_xaxes(\n",
    "    range=[x_min, x_max],  \n",
    ")\n",
    "\n",
    "shap_fig.update_yaxes(\n",
    "    range=[y_min, y_max],\n",
    "    scaleanchor = \"x\",\n",
    "    scaleratio = 1,\n",
    "  );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fe529e4-2897-4efc-b2da-e3aae51dedc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "slider_names = ['slider_name_0','slider_name_1','slider_name_2','slider_name_3','slider_name_4',\n",
    "                'slider_name_5','slider_name_6','slider_name_7','slider_name_8','slider_name_9']\n",
    "\n",
    "slider_figs = [go.Figure() for name in slider_names]\n",
    "\n",
    "slider_annotations = [[\n",
    "    go.layout.Annotation(\n",
    "            #start\n",
    "            x=0, \n",
    "            y=0,\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "            #end\n",
    "            ax=1, \n",
    "            ay=1,\n",
    "            axref = \"x\", \n",
    "            ayref = \"y\",\n",
    "            showarrow=True,\n",
    "            arrowside='start',\n",
    "            arrowhead=2, # type od head [0,8]\n",
    "            arrowsize=1, # head dimension \n",
    "            arrowwidth=2, # arrow dimension\n",
    "            arrowcolor=\"#e9a3c9\",\n",
    "            name=name+'_top',\n",
    "            ),\n",
    "    go.layout.Annotation(\n",
    "            #start\n",
    "            x=0, \n",
    "            y=0,\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "            #end\n",
    "            ax=-1, \n",
    "            ay=-1,\n",
    "            axref = \"x\", \n",
    "            ayref = \"y\",\n",
    "            showarrow=True,\n",
    "            arrowside='start',\n",
    "            arrowhead=2, # type od head [0,8]\n",
    "            arrowsize=1, # head dimension \n",
    "            arrowwidth=2, # arrow dimension\n",
    "            arrowcolor=\"#a1d76a\",\n",
    "            name=name+'_bottom',\n",
    "            )\n",
    "    ] for name in slider_names] \n",
    "\n",
    "for i in range(len(slider_names)):\n",
    "    slider_figs[i].update_layout(\n",
    "        height = 50,\n",
    "        width = 50,\n",
    "        annotations = slider_annotations[i],\n",
    "        margin=go.layout.Margin(\n",
    "            l=0, #left margin\n",
    "            r=0, #right margin\n",
    "            b=0, #bottom margin\n",
    "            t=0  #top margin\n",
    "        ),\n",
    "        plot_bgcolor = '#f2f2f2'\n",
    "    )\n",
    "    \n",
    "    slider_figs[i].update_xaxes(\n",
    "        showgrid = False, \n",
    "        zeroline = False, \n",
    "        visible  = False,\n",
    "    )\n",
    "    \n",
    "    slider_figs[i].update_yaxes(\n",
    "        showgrid = False, \n",
    "        zeroline = False, \n",
    "        visible  = False,\n",
    "    )\n",
    "    \n",
    "    slider_figs[i].update_xaxes(\n",
    "    range=[-1, 1],  \n",
    "    )\n",
    "    \n",
    "    slider_figs[i].update_yaxes(\n",
    "    range=[-1, 1],\n",
    "    scaleanchor = \"x\",\n",
    "    scaleratio = 1\n",
    "    )\n",
    "\n",
    "#slider_figs[0].show(config = {'displayModeBar': False}) #set this into dcc.graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3cac81-3b5e-49d8-962e-b1daf5d57395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10bc1d9e-304f-44af-8a3c-eb0f8da7d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "def wrapper(X):\n",
    "    FFNN_VAE_model.eval()\n",
    "    z, mu, logvar = FFNN_VAE_model(torch.tensor(X).float())\n",
    "    return z.detach().numpy()\n",
    "\n",
    "\n",
    "# use Kernel SHAP to explain test set predictions\n",
    "explainer = shap.KernelExplainer(wrapper, shap.sample(X_train, 100), link=\"identity\")\n",
    "\n",
    "#    data : numpy.array or pandas.DataFrame or shap.common.DenseData or any scipy.sparse matrix\n",
    "#        The background dataset to use for integrating out features. To determine the impact\n",
    "#        of a feature, that feature is set to \"missing\" and the change in the model output\n",
    "#        is observed. Since most models aren't designed to handle arbitrary missing data at test\n",
    "#        time, we simulate \"missing\" by replacing the feature with the values it takes in the\n",
    "#        background dataset. So if the background dataset is a simple sample of all zeros, then\n",
    "#        we would approximate a feature being missing by setting it to zero. For small problems\n",
    "#        this background dataset can be the whole training set, but for larger problems consider\n",
    "#        using a single reference value or using the kmeans function to summarize the dataset.\n",
    "#        Note: for sparse case we accept any sparse matrix but convert to lil format for\n",
    "#        performance.\n",
    "#    link : \"identity\" or \"logit\"\n",
    "#        A generalized linear model link to connect the feature importance values to the model\n",
    "#        output. Since the feature importance values, phi, sum up to the model output, it often makes\n",
    "#        sense to connect them to the output with a link function where link(output) = sum(phi).\n",
    "#        If the model output is a probability then the LogitLink link function makes the feature\n",
    "#        importance values have log-odds units. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "modern-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "mins = np.min(X_train,axis=0)\n",
    "mins = np.round(mins,2)\n",
    "maxs = np.max(X_train,axis=0)\n",
    "maxs = np.round(maxs,2)\n",
    "selected_point = 0\n",
    "change_point = 0\n",
    "query = X_train[selected_point,:]\n",
    "exp_input_values = X_train.mean(axis=0)\n",
    "\n",
    "# main function to output the xai scores\n",
    "def compute_XAI_values(query):\n",
    "    #original_shap\n",
    "    shap_values = explainer.shap_values(query, nsamples='auto')\n",
    "    return explainer.expected_value[0], shap_values[0] ,explainer.expected_value[1], shap_values[1]\n",
    "    \n",
    "\n",
    "exp_x, xai_x, exp_y, xai_y = compute_XAI_values(query)\n",
    "shap_fig.for_each_trace(\n",
    "        lambda trace: trace.update(x=[exp_x], y=[exp_y]) if trace.name == \"expected_value\" else (),\n",
    "        )\n",
    "\n",
    "s = [exp_x, exp_y]\n",
    "#select only the 10 most important features\n",
    "indices = np.argsort(np.sqrt(xai_x[:-1]**2+xai_y[:-1]**2))[-10:][::-1]\n",
    "\n",
    "for i in range(len(slider_names)):\n",
    "    vec = np.array([xai_x[indices][i],xai_y[indices][i]])\n",
    "    vec /= np.linalg.norm(vec)\n",
    "    if query[indices][i]>exp_input_values[indices][i]:\n",
    "        slider_annotations[i][0]['ax'] = vec[0]\n",
    "        slider_annotations[i][0]['ay'] = vec[1]\n",
    "        slider_annotations[i][1]['ax'] = -vec[0]\n",
    "        slider_annotations[i][1]['ay'] = -vec[1]\n",
    "    else:\n",
    "        slider_annotations[i][0]['ax'] = -vec[0]\n",
    "        slider_annotations[i][0]['ay'] = -vec[1]\n",
    "        slider_annotations[i][1]['ax'] = vec[0]\n",
    "        slider_annotations[i][1]['ay'] = vec[1]\n",
    "    slider_figs[i].update_layout(annotations = slider_annotations[i])\n",
    "        \n",
    "# list of the increments of the sliders\n",
    "steps = [1,1,0.01,0.01,1,0.01,1,1,1,1,1,1,1,1,1,0.01,0.01,1,0.01,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d87b07-19f8-4e1c-921d-2548eb981785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "optional-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import dash\n",
    "from jupyter_dash import JupyterDash\n",
    "#import dash_core_components as dcc\n",
    "from dash import dcc\n",
    "#import dash_html_components as html\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output, State\n",
    "from dash.exceptions import PreventUpdate\n",
    "\n",
    "# function to select the ticks of the sliders\n",
    "def select_ticks(m, M, e):\n",
    "    # round values\n",
    "    if m % 1:\n",
    "        m = np.round(m,2)\n",
    "    else: m = int(m)\n",
    "    if M % 1:\n",
    "        M = np.round(M,2)\n",
    "    else: M = int(M)\n",
    "    if e % 1:\n",
    "        e = np.round(e,2)\n",
    "        if np.abs(e) < 0.01:\n",
    "            e = 0\n",
    "    else: e = int(e)\n",
    "        \n",
    "    ticks = dict(sorted({m:{'label':str(m), 'style': {'color': '#a1d76a','font-size':'1rem'}},\n",
    "                         e:{'label':'e','style': {'color': '#800081','font-size':'1rem'}},\n",
    "                         M:{'label':str(M),'style': {'color': '#e9a3c9','font-size':'1rem'}}\n",
    "                        }.items()))\n",
    "    return ticks\n",
    "\n",
    "app = JupyterDash(__name__, meta_tags=[{\"name\": \"viewport\", \"content\": \"width=device-width\"}])\n",
    "\n",
    "app.layout = \\\n",
    "html.Div([\n",
    "    html.Div([\n",
    "        html.H3('Latent Space Explanation'),\n",
    "        ],\n",
    "        id='title',\n",
    "        className='title'),\n",
    "    html.Div([\n",
    "        html.H5('Right: Representation of the latent space. The contributions of the input feature \\\n",
    "        are represented by the black vectors. the bigger the contirbution the longer the vector. The \\\n",
    "        violet triangle is the value for which the contribtuion of all the feature is set to zero. Starting \\\n",
    "        from this value and adding the contribution of each feature it is possible to move to the final final \\\n",
    "        point represented by the black cross. \\n Left: Sliders of the 10 most important features for the selected point. \\\n",
    "        Values ranges from minimum to maximum through the expected value. The expected value e is the value for\\\n",
    "        which the magnitute of the vector for that specific feature is zero. Moving above this value, \\\n",
    "        the dimension of the vecotr follow the pink direction, if the value is below the green one. \\n \\\n",
    "        It is possible to select a new point just by clicking on it in the right plot'),\n",
    "        ],\n",
    "        id='shap_description',\n",
    "        className='subtitle'),\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.Div(\n",
    "                # title above the sliders\n",
    "                [html.Div([\n",
    "                        html.Div([\n",
    "                            html.H5('Name')\n",
    "                        ],\n",
    "                        style={'width':'35%','text-decoration': 'underline'}),\n",
    "                        html.Div([\n",
    "                            html.H5('Slider')\n",
    "                        ],\n",
    "                        style={'width':'45%',\n",
    "                               'text-decoration': 'underline'}),\n",
    "                        html.Div([\n",
    "                            html.H5('Value')\n",
    "                        ],\n",
    "                        style={'width':'10%','text-decoration': 'underline','padding-left': '5px'}),\n",
    "                        html.Div([\n",
    "                            html.H5('Vector')\n",
    "                        ],\n",
    "                        style={'width':'10%','text-decoration': 'underline','padding-left': '5px'})\n",
    "                    ],\n",
    "                id = 'index',\n",
    "                className = 'index')]+[\n",
    "                # cycle for for the 10 sliders\n",
    "                 html.Div([\n",
    "                    html.Div([\n",
    "                        html.H5(str(columns[indices[i]])+' : ', id = 'slider_variable_name_'+str(i))\n",
    "                        ],\n",
    "                        className='variable_name'),\n",
    "                    dcc.Slider(\n",
    "                        min = mins[indices[i]],\n",
    "                        max = maxs[indices[i]],\n",
    "                        value = query[indices[i]],\n",
    "                        step = steps[indices[i]],\n",
    "                        marks = select_ticks(mins[indices[i]], maxs[indices[i]], exp_input_values[indices[i]]),\n",
    "                        id = 'slider_'+str(i),\n",
    "                        className = 'slider'),\n",
    "                    html.Div(id = 'slider_'+str(i)+'_value', className = 'slider_value'),\n",
    "                    html.Div([\n",
    "                        dcc.Graph(\n",
    "                            id = 'slider_graph_'+str(i),\n",
    "                            figure = slider_figs[i],\n",
    "                            config = {'displayModeBar': False})],\n",
    "                        id = 'slider_'+str(i)+'_vector', \n",
    "                        className = 'slider_value'),\n",
    "                    ],\n",
    "                    id = 'variable_'+str(i),\n",
    "                    className = 'variable') for i in range(10)],\n",
    "                id='inputs',\n",
    "                className='inputs'),\n",
    "            html.Div([\n",
    "                dcc.Graph(\n",
    "                    id='space-plot',\n",
    "                    figure=shap_fig,\n",
    "                    config = {\"modeBarButtonsToRemove\": ['select2d','lasso2d'],\n",
    "                              'displaylogo': False}\n",
    "                )\n",
    "                ],\n",
    "                id='graph',\n",
    "                className='graph'),\n",
    "            ],\n",
    "            id='shap_page',\n",
    "            className='shap_page'),\n",
    "        html.Div([\n",
    "            html.H5('Clustering interface: select with the lasso tool on the left and on the rigth the \\\n",
    "            points of interest. In the violin plot at the bottom the yellow distribution is the distribution \\\n",
    "            of the points belonging to the cluster highlighted in the right figure, while the blue one is the \\\n",
    "            distribution of the left one. The features are sorted in descending order from the most separated \\\n",
    "            distributions on the right to the least separated one to the left'),\n",
    "            ],\n",
    "            id='clustering_description',\n",
    "            className='subtitle'),\n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                html.Div([\n",
    "                    dcc.Graph(\n",
    "                        id='left_plot',\n",
    "                        figure=clustering_fig,\n",
    "                        config = {\"modeBarButtonsToRemove\": ['select2d'],\n",
    "                                  'displaylogo': False})\n",
    "                    ],\n",
    "                    className='left_plot'),\n",
    "                html.Div([\n",
    "                    dcc.Graph(\n",
    "                        id='right_plot',\n",
    "                        figure=clustering_fig,\n",
    "                        config = {\"modeBarButtonsToRemove\": ['select2d'],\n",
    "                                  'displaylogo': False})\n",
    "                    ],\n",
    "                    className='right_plot')\n",
    "                ],\n",
    "                id='graphs',\n",
    "                className='graphs'),\n",
    "            html.Div([\n",
    "                dcc.Graph(\n",
    "                    id='violin_plot',\n",
    "                    figure=violin_plot)\n",
    "            ],\n",
    "            className='violin-graph')\n",
    "        ],\n",
    "        id='clustering_page',\n",
    "        className='clustering_page')\n",
    "        ],\n",
    "        id='main_body',\n",
    "        className='main_body'\n",
    "        )\n",
    "    ])\n",
    "\n",
    "#function to update the plot and the values to the 10 most important features\n",
    "@app.callback(\n",
    "    #Output 3 value for slider + the plot\n",
    "    [dash.dependencies.Output('slider_'+str(i)+'_value', 'children') for i in range(10)]+\n",
    "    [dash.dependencies.Output('space-plot', 'figure')],\n",
    "    # As input we only have the 10 values from the sliders\n",
    "    [dash.dependencies.Input('slider_'+str(i), 'value') for i in range(10)],\n",
    "    dash.dependencies.State('space-plot', 'relayoutData'))\n",
    "def update_output(value0,value1,value2,value3,value4,value5,value6,value7,value8,value9,fig_data):\n",
    "    v = [value0,value1,value2,value3,value4,value5,value6,value7,value8,value9]\n",
    "    # query is the value to explain \n",
    "    # in this for loop change the value of the query according to the slider values\n",
    "    query = X_train[selected_point,:]\n",
    "    # Problem when selecting a new point: the slider values changes one at a time and this function is triggered 10 times!!! one for every changes with the older values\n",
    "    #global change_point\n",
    "    #if change_point:\n",
    "    #    if dash.callback_context.triggered[0]['prop_id'] != 'slider_9.value':\n",
    "    #        raise PreventUpdate\n",
    "    #    else: change_point = 0\n",
    "    for i in range(len(v)):\n",
    "        query[indices[i]] = v[i]\n",
    "    # compute xai values\n",
    "    exp_x, xai_x, exp_y, xai_y = compute_XAI_values(query)\n",
    "    \n",
    "    #compute new z position\n",
    "    with torch.no_grad():\n",
    "        z , _ = FFNN_VAE_model.encode(torch.tensor(query).float())\n",
    "        z = z.numpy()\n",
    "    #update the scatter plot and the vector explanations\n",
    "    shap_fig.for_each_trace(\n",
    "        lambda trace: trace.update(x=[z[0]], y=[z[1]]) if trace.name == \"pointer\" else (),\n",
    "        )\n",
    "    s = [exp_x, exp_y]\n",
    "    for i in range(len(v)):\n",
    "        #start\n",
    "        annotations[i]['x'] = s[0]\n",
    "        annotations[i]['y'] = s[1]\n",
    "        #end\n",
    "        s[0] += xai_x[indices[i]]\n",
    "        s[1] += xai_y[indices[i]]\n",
    "        annotations[i]['ax'] = s[0]\n",
    "        annotations[i]['ay'] = s[1]\n",
    "        annotations[i]['hovertext'] = str(columns[indices[i]])\n",
    "    annotations[-1]['x'] = s[0]\n",
    "    annotations[-1]['y'] = s[1]\n",
    "    annotations[-1]['ax'] = z[0]\n",
    "    annotations[-1]['ay'] = z[1]\n",
    "    # update with zoom level as selected by the user\n",
    "    try:\n",
    "        shap_fig.update_layout({'xaxis':{'range':[fig_data['xaxis.range[0]'],fig_data['xaxis.range[1]']]},\n",
    "                           'yaxis':{'range':[fig_data['yaxis.range[0]'],fig_data['yaxis.range[1]']]},\n",
    "                          },\n",
    "                          annotations = annotations)\n",
    "    except: shap_fig.update_layout(annotations = annotations)\n",
    "    # the output must be a list [slider_value]*10+[fig]\n",
    "    #v = np.array(v)\n",
    "    #xai_x = xai_x[indices]\n",
    "    #xai_y = xai_y[indices]\n",
    "    out = v\n",
    "    #out = list(np.vstack(v).transpose().ravel())\n",
    "    # round the numbers\n",
    "    for i in range(len(out)):\n",
    "        if out[i]%1:\n",
    "            out[i] = np.round(out[i],2)\n",
    "        else: out[i] = int(out[i])\n",
    "    return out + [shap_fig]\n",
    "    \n",
    "# select the point\n",
    "@app.callback(\n",
    "    sum([[dash.dependencies.Output('slider_variable_name_'+str(i), 'children'),\n",
    "      dash.dependencies.Output('slider_'+str(i), 'min'),\n",
    "      dash.dependencies.Output('slider_'+str(i), 'max'),\n",
    "      dash.dependencies.Output('slider_'+str(i), 'value'),\n",
    "      dash.dependencies.Output('slider_'+str(i), 'step'),\n",
    "      dash.dependencies.Output('slider_'+str(i), 'marks'),\n",
    "     ] for i in range(10)],[])+\n",
    "    [dash.dependencies.Output('slider_graph_'+str(i), 'figure') for i in range(10)],\n",
    "    dash.dependencies.Input('space-plot', 'clickData'), prevent_initial_call=True\n",
    "    )\n",
    "def display_click_data(clickData):\n",
    "    global selected_point\n",
    "    selected_point = clickData['points'][0]['pointIndex']\n",
    "    global change_point\n",
    "    change_point = 1\n",
    "    query = X_train[selected_point,:]\n",
    "    #print(selected_point)\n",
    "    exp_x, xai_x, exp_y, xai_y = compute_XAI_values(query)\n",
    "    global shap_fig\n",
    "    shap_fig.for_each_trace(\n",
    "        lambda trace: trace.update(x=[exp_x], y=[exp_y]) if trace.name == \"expected_value\" else (),\n",
    "    )\n",
    "    s = [exp_x, exp_y]\n",
    "    #select only the 10 most important features\n",
    "    global indices\n",
    "    indices = np.argsort(np.sqrt(xai_x[:-1]**2+xai_y[:-1]**2))[-10:][::-1]\n",
    "    \n",
    "    for i in range(len(slider_names)):\n",
    "        vec = np.array([xai_x[indices][i],xai_y[indices][i]])\n",
    "        vec /= np.linalg.norm(vec)\n",
    "        if query[indices][i]>exp_input_values[indices][i]:\n",
    "            slider_annotations[i][0]['ax'] = vec[0]\n",
    "            slider_annotations[i][0]['ay'] = vec[1]\n",
    "            slider_annotations[i][1]['ax'] = -vec[0]\n",
    "            slider_annotations[i][1]['ay'] = -vec[1]\n",
    "        else:\n",
    "            slider_annotations[i][0]['ax'] = -vec[0]\n",
    "            slider_annotations[i][0]['ay'] = -vec[1]\n",
    "            slider_annotations[i][1]['ax'] = vec[0]\n",
    "            slider_annotations[i][1]['ay'] = vec[1]\n",
    "        slider_figs[i].update_layout(annotations = slider_annotations[i])\n",
    "    return sum([[str(X_train_df.columns[indices[i]])+' : ',\n",
    "                 mins[indices[i]],\n",
    "                 maxs[indices[i]],\n",
    "                 query[indices[i]],\n",
    "                 steps[indices[i]],\n",
    "                 select_ticks(mins[indices[i]],\n",
    "                              maxs[indices[i]],\n",
    "                              exp_input_values[indices[i]])\n",
    "                ] for i in range(10)],[])+slider_figs\n",
    "\n",
    "def update_violin_plot(idx_l,idx_r):\n",
    "    global X_train_df\n",
    "    x_l = X_train_df.iloc[idx_l==1,:].copy()\n",
    "    x_r = X_train_df.iloc[idx_r==1,:].copy()\n",
    "    ma = np.mean(x_l.to_numpy(),axis=0)\n",
    "    mb = np.mean(x_r.to_numpy(),axis=0)\n",
    "    indices = np.argsort(np.abs(ma-mb))[-15:]\n",
    "    x_l = x_l.iloc[:,indices].melt()\n",
    "    x_r = x_r.iloc[:,indices].melt()\n",
    "    global violin_plot\n",
    "    violin_plot.for_each_trace(\n",
    "        lambda trace: trace.update(x=x_l['variable'], y=x_l['value']) if trace.name == \"left\" else (trace.update(x=x_r['variable'], y=x_r['value'])),\n",
    "    )\n",
    "    return violin_plot\n",
    "\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('violin_plot', 'figure'),\n",
    "    [dash.dependencies.Input('left_plot', 'selectedData'),\n",
    "     dash.dependencies.Input('right_plot', 'selectedData')]\n",
    "    )\n",
    "def compute_violin(selectedData_left, selectedData_right):\n",
    "    if selectedData_left:\n",
    "        selected_points_left = [selectedData_left['points'][i]['pointIndex'] for i in range(len(selectedData_left['points']))]\n",
    "        if selectedData_right:\n",
    "            selected_points_right = [selectedData_right['points'][i]['pointIndex'] for i in range(len(selectedData_right['points']))]\n",
    "            idx_l = np.zeros(len(X_train_df))\n",
    "            idx_r = np.zeros(len(X_train_df))\n",
    "            idx_r[selected_points_right]=1\n",
    "            idx_l[selected_points_left]=1\n",
    "            return update_violin_plot(idx_l,idx_r)\n",
    "        else:\n",
    "            idx_l = np.zeros(len(X_train_df))\n",
    "            idx_l[selected_points_left]=1\n",
    "            idx_r = np.ones(len(X_train_df))\n",
    "            return update_violin_plot(idx_l,idx_r)\n",
    "    else:\n",
    "        if selectedData_right:\n",
    "            selected_points_right = [selectedData_right['points'][i]['pointIndex'] for i in range(len(selectedData_right['points']))]\n",
    "            idx_l = np.ones(len(X_train_df))\n",
    "            idx_r = np.zeros(len(X_train_df))\n",
    "            idx_r[selected_points_right]=1\n",
    "            return update_violin_plot(idx_l,idx_r)\n",
    "        else:\n",
    "            violin_plot.for_each_trace(\n",
    "                lambda trace: trace.update(x=X_test_df.melt()['variable'], y=X_train_df.melt()['value']) if trace.name == \"right\" else \n",
    "                             (trace.update(x=X_test_df.melt()['variable'], y=X_train_df.melt()['value'])),\n",
    "            )\n",
    "            return violin_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d1e0c86-7542-4834-b6a1-6216bdbeface",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8090/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean of empty slice.\n",
      "invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# run the app\n",
    "app.run_server(mode='external',\n",
    "               port=8090, \n",
    "               dev_tools_ui=True, \n",
    "               debug=True,\n",
    "               dev_tools_hot_reload=True,\n",
    "               threaded=True,\n",
    "               #host='127.0.0.1:2595'\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d651faeb-390a-4d20-9563-92d252138329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc7bcd-f11c-4f50-8741-564c53c2da00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
